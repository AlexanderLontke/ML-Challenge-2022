{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcB2DWmKW2Bo"
      },
      "source": [
        "### Setup environment ###\n",
        "\n",
        "As a fist step, we install and import all necessary modules and set a deterministic random seed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "yWPzobadX2-p",
        "outputId": "cec628d0-4665-4ad2-a946-24bc4a86cfeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.1)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BET8zXQvW2Bq",
        "outputId": "2781193f-10de-4d8d-de19-4d833424ac28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f41884e09f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datetime import datetime\n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "from torch import nn\n",
        "\n",
        "# init deterministic seed\n",
        "seed_value = 123\n",
        "np.random.seed(seed_value)  # set numpy seed\n",
        "torch.manual_seed(seed_value)  # set pytorch seed CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a mapping from prediction label to int and vice versa that will be used throughout the notebook."
      ],
      "metadata": {
        "id": "3vnPjeBI1he3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper mappings between classes and integers\n",
        "classes_to_int = {\n",
        "    \"AnnualCrop\": 0,\n",
        "    \"Forest\": 1,\n",
        "    \"HerbaceousVegetation\": 2,\n",
        "    \"Highway\": 3,\n",
        "    \"Industrial\": 4,\n",
        "    \"Pasture\": 5,\n",
        "    \"PermanentCrop\": 6,\n",
        "    \"Residential\": 7,\n",
        "    \"River\": 8,\n",
        "    \"SeaLake\": 9,\n",
        "}\n",
        "classes_to_label = {\n",
        "    0: \"AnnualCrop\",\n",
        "    1: \"Forest\",\n",
        "    2: \"HerbaceousVegetation\",\n",
        "    3: \"Highway\",\n",
        "    4: \"Industrial\",\n",
        "    5: \"Pasture\",\n",
        "    6: \"PermanentCrop\",\n",
        "    7: \"Residential\",\n",
        "    8: \"River\",\n",
        "    9: \"SeaLake\",\n",
        "}\n"
      ],
      "metadata": {
        "id": "09mSdDJp1hOR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data ##\n",
        "We download the training dataset and unzip the contents. "
      ],
      "metadata": {
        "id": "8Hh0uxEa1vYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# This can take a few minutes\n",
        "!wget https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\n",
        "!unzip /content/EuroSATallBands.zip"
      ],
      "metadata": {
        "id": "AvIlMOAjZkoI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L18bFfwSW2Bs"
      },
      "source": [
        "## Define directory paths ##\n",
        "\n",
        "We define the directories in which models are stored and the raw data can be found and the submission data is stored. Additionally, we also create the folder where the trained models should be stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DPHjQ9IlW2Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cf65e7-a9dc-40d4-9985-1dc4af827208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir models\n",
        "MODELS_PATH = \"models\"\n",
        "DATA_PATH = \"ds/images/remote_sensing/otherDatasets/sentinel_2/tif\"\n",
        "SUBMISSION_DATA_PATH = \"submission_dataset/testset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whfZAqgpW2Bs"
      },
      "source": [
        "## Data Loading ##\n",
        "\n",
        "For the data loading we use a custom torch dataset which loads data into memory. We also integrate normalization (mean 0, std 1) into the data loading."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all available files for training\n",
        "samples = glob.glob(os.path.join(DATA_PATH, \"*\", \"*.tif\"))\n",
        "print(len(samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Kx9B7z2GXS",
        "outputId": "11efa111-0de5-4749-da4f-a0536240cd5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we create our dataset, we need to use a normalization method. To create the normalizer we first compute the means and standard deviations over all bands from all samples. In this notebook we can make use of pre-computed values."
      ],
      "metadata": {
        "id": "IeA5yYNF2IQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create normalizer for 12 bands with precomputed means and standard deviations across all bands\n",
        "means_tuple = (\n",
        "    1353.7269257269966,\n",
        "    1117.2022923538773,\n",
        "    1041.8847248444733,\n",
        "    946.5542548737702,\n",
        "    1199.1886644965277,\n",
        "    2003.0067999222367,\n",
        "    2374.008444688585,\n",
        "    2301.2204385489003,\n",
        "    732.1819500777633,\n",
        "    1820.6963775318286,\n",
        "    1118.2027229275175,\n",
        "    2599.7829373281975,\n",
        ")\n",
        "stds_tuple = (\n",
        "    65.29657739037496,\n",
        "    153.77375864458085,\n",
        "    187.69931299271406,\n",
        "    278.1246366855392,\n",
        "    227.92409611864002,\n",
        "    355.9331571735718,\n",
        "    455.13290021052626,\n",
        "    530.7795614455541,\n",
        "    98.92998227431653,\n",
        "    378.16138952053035,\n",
        "    303.10651348740964,\n",
        "    502.16376466306053\n",
        ")\n",
        "train_normalizer = torchvision.transforms.Normalize(means_tuple, stds_tuple)"
      ],
      "metadata": {
        "id": "zaSuc93i2MDE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make use of the previously created normalizer for our custom dataset."
      ],
      "metadata": {
        "id": "EELvqwqc2mZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In-memory dataset\n",
        "class InMemoryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, normalizer=train_normalizer):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        for sample in tqdm(samples, desc=\"Loading training samples\"):\n",
        "            # Extract bands\n",
        "            with rio.open(sample, \"r\") as d:\n",
        "                img = d.read([1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13])\n",
        "            tens = torch.tensor(img.astype(int))\n",
        "\n",
        "            # Normalize\n",
        "            tens = normalizer(tens.float())\n",
        "\n",
        "            # Extract label\n",
        "            label = sample.split(\"/\")[-1].split(\"_\")[0]\n",
        "            label_id = classes_to_int[label]\n",
        "            self.x.append(tens)\n",
        "            self.y.append(label_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # Load data into custom torch data set\n",
        "dataset = InMemoryDataset(samples)"
      ],
      "metadata": {
        "id": "SThQIDKmXE0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d372cb0-7f7a-4cbe-9da6-9888c4e088be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading training samples: 100%|██████████| 27000/27000 [01:52<00:00, 239.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, we could make use of the method below, to recompute the means and standard deviations from scratch:"
      ],
      "metadata": {
        "id": "FSpKqw4R2U0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_normalizer_for_dataset(dataset, verbose: bool = False) -> torchvision.transforms.transforms.Normalize:\n",
        "    \"\"\"\n",
        "    Method returning a normalizer which sets mean to 0 and std to 1 for dataset\n",
        "    :param dataset: Dataset to compute statistics for the normalizer from\n",
        "    :param verbose: set True if you want to print the mean and std vectors\n",
        "    :return: normalizer\n",
        "    \"\"\"\n",
        "    # ONLY EXECUTE IF NEEDED: Compute means and Standard deviation for all bands across all images\n",
        "    band_means = {}\n",
        "    band_stds = {}\n",
        "    # Data needs to be not normalized for this computation\n",
        "    for x in dataset.x:\n",
        "        means = torch.mean(x.float(), dim=(1, 2))\n",
        "        stds = torch.std(x.float(), dim=(1, 2))\n",
        "\n",
        "        for i, mean in enumerate(means):\n",
        "            band_means[i] = band_means.get(i, 0) + float(mean)\n",
        "\n",
        "        for i, std in enumerate(stds):\n",
        "            band_stds[i] = band_stds.get(i, 0) + float(std)\n",
        "\n",
        "    means_tuple = tuple()\n",
        "    for value in band_means.values():\n",
        "        means_tuple += (value / len(dataset.x),)\n",
        "\n",
        "    stds_tuple = tuple()\n",
        "    for value in band_stds.values():\n",
        "        stds_tuple += (value / len(dataset.x),)\n",
        "    if verbose:\n",
        "        print(means_tuple)\n",
        "        print(stds_tuple)\n",
        "\n",
        "    normalizer = torchvision.transforms.Normalize(means_tuple, stds_tuple)\n",
        "    return normalizer"
      ],
      "metadata": {
        "id": "TgE3H_nyXO2w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g39hSQRW2Bt"
      },
      "source": [
        "### Load Training Data ###\n",
        "\n",
        "Since we are preparing to create a submission, we are not splitting the data into a training and test set, but instead use the entire dataset for training purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H8T0kGCDW2Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226dbeee-cb31-487e-83ce-b8f72e77d673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset: 27000\n"
          ]
        }
      ],
      "source": [
        "print(f\"length of dataset: {len(dataset)}\")\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0dPA_-dyW2Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e68522c-c7d7-4dd2-d797-2d20c3928ed4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 12, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Check shape of sample\n",
        "next(iter(train_dataloader))[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VyxmwszW2Bv"
      },
      "source": [
        "## Define Model ##\n",
        "\n",
        "In this section we define our model for the challenge."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Model used for ML-Challenge\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Model definition\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 24, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(24, 72, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(72 * 13 * 13, 512)\n",
        "        self.fc2 = nn.Linear(512, 124)\n",
        "        self.fc3 = nn.Linear(124, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Model forward pass\n",
        "        :param x: List of image samples\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        \n",
        "net = Net()"
      ],
      "metadata": {
        "id": "Z-F47NHWXBJs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also check how many parameters are to be trained."
      ],
      "metadata": {
        "id": "DMk5y5TO3Hhw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "feovoIxMW2Bw",
        "outputId": "ff9c1d1d-c6f1-4e40-a536-f48b86ba85ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of to be trained model parameters: 6345886.\n"
          ]
        }
      ],
      "source": [
        "num_params = 0\n",
        "for param in net.parameters():\n",
        "    num_params += param.numel()\n",
        "\n",
        "print(\"Number of to be trained model parameters: {}.\".format(num_params))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then move the created model to the GPU device if cuda is available."
      ],
      "metadata": {
        "id": "Kj5LXr9y3K3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ],
      "metadata": {
        "id": "JTyHf8N7biI2",
        "outputId": "00f5fbd5-f7f8-4c9d-99ea-bc4d47cb2b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] notebook with cuda computation enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "DNN3-F-rbdll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0984f3e-0155-4237-d892-72252233d373"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 22 14:01:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    42W / 250W |    953MiB / 16280MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBym1xNJW2Bw"
      },
      "source": [
        "## Train Model ##\n",
        "\n",
        "In this section we train our model with a cross-entropy loss utilizing stochasting gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ccUeWkhSW2Bw"
      },
      "outputs": [],
      "source": [
        "# Define optimization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "tS806fiBbfBW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "id": "qxgfdpP0W2Bw",
        "outputId": "9c2ca131-5661-4e37-e625-c1041babb936",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20220522-14:01:29] epoch: 1 train-loss: 1.2868243229897667\n",
            "[LOG 20220522-14:01:33] epoch: 2 train-loss: 0.7116308804089424\n",
            "[LOG 20220522-14:01:38] epoch: 3 train-loss: 0.49656307160571855\n",
            "[LOG 20220522-14:01:43] epoch: 4 train-loss: 0.41015020154098764\n",
            "[LOG 20220522-14:01:47] epoch: 5 train-loss: 0.3490261896667887\n",
            "[LOG 20220522-14:01:52] epoch: 6 train-loss: 0.3127459866740692\n",
            "[LOG 20220522-14:01:56] epoch: 7 train-loss: 0.2791673368046069\n",
            "[LOG 20220522-14:02:01] epoch: 8 train-loss: 0.26028044239322157\n",
            "[LOG 20220522-14:02:06] epoch: 9 train-loss: 0.2379735706824262\n",
            "[LOG 20220522-14:02:10] epoch: 10 train-loss: 0.21573348855379068\n",
            "[LOG 20220522-14:02:15] epoch: 11 train-loss: 0.20492813506680077\n",
            "Saving model\n",
            "[LOG 20220522-14:02:19] epoch: 12 train-loss: 0.19337301291701917\n",
            "[LOG 20220522-14:02:24] epoch: 13 train-loss: 0.1736706042600469\n",
            "[LOG 20220522-14:02:29] epoch: 14 train-loss: 0.1616321883883804\n",
            "[LOG 20220522-14:02:33] epoch: 15 train-loss: 0.14961641211221569\n",
            "[LOG 20220522-14:02:38] epoch: 16 train-loss: 0.13460231049789637\n",
            "[LOG 20220522-14:02:43] epoch: 17 train-loss: 0.12759870652692012\n",
            "[LOG 20220522-14:02:47] epoch: 18 train-loss: 0.11881144120583037\n",
            "[LOG 20220522-14:02:52] epoch: 19 train-loss: 0.11436150072945803\n",
            "[LOG 20220522-14:02:56] epoch: 20 train-loss: 0.10199247420681597\n",
            "[LOG 20220522-14:03:01] epoch: 21 train-loss: 0.10116198278469214\n",
            "Saving model\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train_epoch_losses = []\n",
        "validation_epoch_losses = []\n",
        "\n",
        "epochs = 21\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    # init collection of mini-batch losses\n",
        "    train_mini_batch_losses = []\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader, 0):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # collect mini-batch reconstruction loss\n",
        "        train_mini_batch_losses.append(loss.data.item())\n",
        "            \n",
        "    # Per epoch store the training... \n",
        "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
        "    train_epoch_losses.append(train_epoch_loss)\n",
        "\n",
        "    # ...print statistics, ...\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "    print(f\"[LOG {now}] epoch: {epoch+1} train-loss: {train_epoch_loss}\")\n",
        "    # ...and save the model every 10 epochs\n",
        "    if (epoch) % 10 == 0 and epoch != 0:\n",
        "        if not os.path.exists(MODELS_PATH):\n",
        "            os.mkdir(MODELS_PATH)\n",
        "        print(\"Saving model\")\n",
        "        torch.save(\n",
        "            net.state_dict(), os.path.join(MODELS_PATH, f\"new_model_{epoch}.pth\")\n",
        "        )\n",
        "print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Delx76bW2By"
      },
      "source": [
        "## Create submission ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3l325siW2By"
      },
      "source": [
        "#### Load Model\n",
        "\n",
        "Our final model weights can be found in the file 'final_model_weights.pth'. If you are using this notebook in Google colab, you will need to upload the file to the \"models\" folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YHQQ-RotW2By",
        "outputId": "c737d509-1a4e-4539-a6d1-c7d0754939ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_model_weights.pth  new_model_10.pth  new_model_20.pth\n"
          ]
        }
      ],
      "source": [
        "!ls models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HLBVLa6PW2By",
        "outputId": "20544c91-50ca-4f48-f32b-23682906c425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "selected_model_path = \"final_model_weights.pth\"\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(os.path.join(MODELS_PATH, selected_model_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIWXQ0WlW2By"
      },
      "source": [
        "#### Load submission data\n",
        "\n",
        "We first download the data from a Github repository and then define a custom dataset where the bands are brought in order. We normalize the data with precomputed means and standard deviations over all submission data samples of all bands, since this dataset is slightly different than the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rbngz/submission_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36a-j4uxqTS",
        "outputId": "fa9198c9-ccf9-4757-d9d4-d3ef3b30f6f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'submission_dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_means_tuple = (\n",
        "    380.17328711583616,\n",
        "    400.1497676971955,\n",
        "    628.8646132355601,\n",
        "    578.870857455104,\n",
        "    943.4272711885449,\n",
        "    1826.2433534560898,\n",
        "    2116.6662455740857,\n",
        "    2205.972884006897,\n",
        "    2266.934157142567,\n",
        "    1487.6910683644517,\n",
        "    959.236167229867,\n",
        "    2281.1860589241937\n",
        ")\n",
        "submission_stds_tuple = (\n",
        "    115.17434877174112,\n",
        "    209.14842754591166,\n",
        "    241.20653977105658,\n",
        "    301.1056228200069,\n",
        "    269.5139533673432,\n",
        "    420.2497496130561,\n",
        "    503.8183661547185,\n",
        "    598.040304209199,\n",
        "    403.93781724898935,\n",
        "    398.143166872752,\n",
        "    342.44079144555366,\n",
        "    529.4133153492427\n",
        ")\n",
        "submission_normalizer = torchvision.transforms.Normalize(\n",
        "    submission_means_tuple, submission_stds_tuple\n",
        ")"
      ],
      "metadata": {
        "id": "3LIdPRDwzhcZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubmissionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, submission_samples, normalizer=submission_normalizer):\n",
        "        self.x = []\n",
        "        for _, submission_sample in tqdm(\n",
        "            sorted(\n",
        "                {\n",
        "                    # Sort files by index\n",
        "                    int(re.findall(\"\\d+\", submission_sample)[0]): submission_sample\n",
        "                    for submission_sample in submission_samples\n",
        "                }.items()\n",
        "            ),\n",
        "            desc=\"Loading submission samples\"\n",
        "        ):\n",
        "            # Extract bands\n",
        "            img = np.load(submission_sample)\n",
        "\n",
        "            # SWAP BANDS\n",
        "            tmp = img[:, :, 8].copy()\n",
        "            img = np.delete(img, 8, axis=2)\n",
        "            img = np.insert(img, 11, tmp, axis=2)\n",
        "\n",
        "            tens = torch.from_numpy(img.astype(int))\n",
        "            tens = tens.permute(2, 1, 0)\n",
        "\n",
        "            # Normalize\n",
        "            tens = normalizer(tens.float())\n",
        "            self.x.append(tens)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "LszqRhIs6f4X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": false,
        "id": "RoklI8Y-W2By",
        "outputId": "8c370d64-b4c0-47be-f330-f5f9db5b7787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading submission samples: 100%|██████████| 4232/4232 [00:05<00:00, 817.94it/s]\n"
          ]
        }
      ],
      "source": [
        "submission_testset_samples = glob.glob(os.path.join(SUBMISSION_DATA_PATH, \"*.npy\"))\n",
        "submission_dataset = SubmissionDataset(submission_testset_samples)\n",
        "\n",
        "submission_dataloader = torch.utils.data.DataLoader(\n",
        "    submission_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHd-n0wuW2Bz"
      },
      "source": [
        "#### Create submission ####\n",
        "\n",
        "Finally, we create a csv file that we are able to upload to kaggle. :)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(net, submission_dataloader, filename: str = \"submission.csv\"):\n",
        "    \"\"\"\n",
        "    Helper method which creates a Kaggle submission from a given model and\n",
        "    :param net:\n",
        "    :param submission_dataloader:\n",
        "    :param filename:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    submission_results = []\n",
        "\n",
        "    index = 0\n",
        "    with torch.no_grad():\n",
        "        for images in iter(submission_dataloader):\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            label = classes_to_label[int(predicted[0])]\n",
        "            # Print predicted sample every once in a while\n",
        "            if index % 1000 == 0:\n",
        "                print(f\"Predicted: {label}\")\n",
        "            submission_results.append([index, label])\n",
        "            index += 1\n",
        "\n",
        "    # field names\n",
        "    fields = [\"test_id\", \"label\"]\n",
        "\n",
        "    # writing to csv file\n",
        "    with open(filename, \"w\") as csvfile:\n",
        "        # creating a csv writer object\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # writing the fields\n",
        "        csv_writer.writerow(fields)\n",
        "\n",
        "        # writing the data rows\n",
        "        csv_writer.writerows(submission_results)\n",
        "    print(f\"Submission was written to ./{filename}\")\n",
        "\n",
        "create_submission(net, submission_dataloader)"
      ],
      "metadata": {
        "id": "RZGkmCDAXgw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d32196c-8e93-465d-f694-bf8937fb7d84"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Highway\n",
            "Predicted: Highway\n",
            "Predicted: River\n",
            "Predicted: Pasture\n",
            "Predicted: SeaLake\n",
            "Submission was written to ./submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X4rSbJI9W2Bz",
        "outputId": "94600159-59ce-468b-cd96-c31f04644099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeaLake                 1024\n",
              "AnnualCrop               706\n",
              "Highway                  515\n",
              "HerbaceousVegetation     385\n",
              "PermanentCrop            320\n",
              "River                    284\n",
              "Pasture                  273\n",
              "Industrial               268\n",
              "Forest                   264\n",
              "Residential              193\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"submission.csv\")\n",
        "df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E56onv8yW2Bz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "52335bc23b2686a5a24812a5c3b72ed0d36239717828f34470b0e14de89a5f4e"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "colab_submission_notebook.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}