{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcB2DWmKW2Bo"
      },
      "source": [
        "### Setup environment ###\n",
        "\n",
        "Here we import all necessary modules for our model including our own python modules."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "yWPzobadX2-p",
        "outputId": "e56bdfa8-9766-4ba7-9a25-087c2c62fa2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.1)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BET8zXQvW2Bq",
        "outputId": "37e1f007-7c53-4a21-b6e7-f4b569cb8f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4ca76e24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datetime import datetime\n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "from torch import nn\n",
        "\n",
        "# init deterministic seed\n",
        "seed_value = 1234\n",
        "np.random.seed(seed_value)  # set numpy seed\n",
        "torch.manual_seed(seed_value)  # set pytorch seed CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L18bFfwSW2Bs"
      },
      "source": [
        "## Define directory paths ##\n",
        "\n",
        "We define the directories in which models are stored, the raw data can be found and the submission data is stored."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\n",
        "!unzip /content/EuroSATallBands.zip\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "AvIlMOAjZkoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPHjQ9IlW2Bs"
      },
      "outputs": [],
      "source": [
        "MODELS_PATH = \"models\"\n",
        "DATA_PATH = \"ds/images/remote_sensing/otherDatasets/sentinel_2/tif\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whfZAqgpW2Bs"
      },
      "source": [
        "## Data Loading ##\n",
        "\n",
        "For the data loading we use a custom torch dataset which loads data into memory. We also integrate normalization (mean 0, std 1) into the data loading."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper mappings between classes and integers\n",
        "classes_to_int = {\n",
        "    \"AnnualCrop\": 0,\n",
        "    \"Forest\": 1,\n",
        "    \"HerbaceousVegetation\": 2,\n",
        "    \"Highway\": 3,\n",
        "    \"Industrial\": 4,\n",
        "    \"Pasture\": 5,\n",
        "    \"PermanentCrop\": 6,\n",
        "    \"Residential\": 7,\n",
        "    \"River\": 8,\n",
        "    \"SeaLake\": 9,\n",
        "}\n",
        "classes_to_label = {\n",
        "    0: \"AnnualCrop\",\n",
        "    1: \"Forest\",\n",
        "    2: \"HerbaceousVegetation\",\n",
        "    3: \"Highway\",\n",
        "    4: \"Industrial\",\n",
        "    5: \"Pasture\",\n",
        "    6: \"PermanentCrop\",\n",
        "    7: \"Residential\",\n",
        "    8: \"River\",\n",
        "    9: \"SeaLake\",\n",
        "}\n",
        "\n",
        "# Create normalizer for 12 bands with precomputed means and standard deviations across all bands\n",
        "means_tuple = (\n",
        "    1353.7269257269966,\n",
        "    1117.2022923538773,\n",
        "    1041.8847248444733,\n",
        "    946.5542548737702,\n",
        "    1199.1886644965277,\n",
        "    2003.0067999222367,\n",
        "    2374.008444688585,\n",
        "    2301.2204385489003,\n",
        "    732.1819500777633,\n",
        "    1820.6963775318286,\n",
        "    1118.2027229275175,\n",
        "    2599.7829373281975,\n",
        ")\n",
        "stds_tuple = (\n",
        "    65.29657739037496,\n",
        "    153.77375864458085,\n",
        "    187.69931299271406,\n",
        "    278.1246366855392,\n",
        "    227.92409611864002,\n",
        "    355.9331571735718,\n",
        "    455.13290021052626,\n",
        "    530.7795614455541,\n",
        "    98.92998227431653,\n",
        "    378.16138952053035,\n",
        "    303.10651348740964,\n",
        "    502.16376466306053\n",
        ")\n",
        "train_normalizer = torchvision.transforms.Normalize(means_tuple, stds_tuple)\n",
        "\n",
        "\n",
        "#In-memory dataset\n",
        "class InMemoryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, normalizer=train_normalizer):\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "        for sample in tqdm(samples, desc=\"Loading training samples\"):\n",
        "            # Extract bands\n",
        "            with rio.open(sample, \"r\") as d:\n",
        "                img = d.read([1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13])\n",
        "            tens = torch.tensor(img.astype(int))\n",
        "\n",
        "            # Normalize\n",
        "            tens = normalizer(tens.float())\n",
        "\n",
        "            # Extract label\n",
        "            label = sample.split(\"/\")[-1].split(\"_\")[0]\n",
        "            label_id = classes_to_int[label]\n",
        "            self.x.append(tens)\n",
        "            self.y.append(label_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "SThQIDKmXE0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_normalizer_for_dataset(dataset, verbose: bool = False) -> torchvision.transforms.transforms.Normalize:\n",
        "    \"\"\"\n",
        "    Method returning a normalizer which sets mean to 0 and std to 1 for dataset\n",
        "    :param dataset: Dataset to compute statistics for the normalizer from\n",
        "    :param verbose: set True if you want to print the mean and std vectors\n",
        "    :return: normalizer\n",
        "    \"\"\"\n",
        "    # ONLY EXECUTE IF NEEDED: Compute means and Standard deviation for all bands across all images\n",
        "    band_means = {}\n",
        "    band_stds = {}\n",
        "    # Data needs to be not normalized for this computation\n",
        "    for x in dataset.x:\n",
        "        means = torch.mean(x.float(), dim=(1, 2))\n",
        "        stds = torch.std(x.float(), dim=(1, 2))\n",
        "\n",
        "        for i, mean in enumerate(means):\n",
        "            band_means[i] = band_means.get(i, 0) + float(mean)\n",
        "\n",
        "        for i, std in enumerate(stds):\n",
        "            band_stds[i] = band_stds.get(i, 0) + float(std)\n",
        "\n",
        "    means_tuple = tuple()\n",
        "    for value in band_means.values():\n",
        "        means_tuple += (value / len(dataset.x),)\n",
        "\n",
        "    stds_tuple = tuple()\n",
        "    for value in band_stds.values():\n",
        "        stds_tuple += (value / len(dataset.x),)\n",
        "    if verbose:\n",
        "        print(means_tuple)\n",
        "        print(stds_tuple)\n",
        "\n",
        "    normalizer = torchvision.transforms.Normalize(means_tuple, stds_tuple)\n",
        "    return normalizer"
      ],
      "metadata": {
        "id": "TgE3H_nyXO2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5CiUbnGzW2Bt"
      },
      "outputs": [],
      "source": [
        "# Get a list of all available files for training\n",
        "samples = glob.glob(os.path.join(DATA_PATH, \"*\", \"*.tif\"))\n",
        "print(len(samples))\n",
        "\n",
        "# Load data into custom torch data set\n",
        "dataset = InMemoryDataset(samples)\n",
        "# Uncomment to create normalizer from scratch\n",
        "# dataset = InMemoryDataset(samples, lambda x:x)\n",
        "# normalizer = create_normalizer_for_dataset(dataset, verbose=True)\n",
        "# del dataset\n",
        "# dataset = InMemoryDataset(samples, normalizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g39hSQRW2Bt"
      },
      "source": [
        "### Load Training Data ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8T0kGCDW2Bu"
      },
      "outputs": [],
      "source": [
        "print(f\"length of dataset: {len(dataset)}\")\n",
        "\n",
        "batch_size = 128\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dPA_-dyW2Bu"
      },
      "outputs": [],
      "source": [
        "# Check shape of sample\n",
        "next(iter(train_dataloader))[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VyxmwszW2Bv"
      },
      "source": [
        "## Define Model ##\n",
        "\n",
        "In this section we define our model for the challenge."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "    Model used for ML-Challenge\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Model definition\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 24, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(24, 72, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(72 * 13 * 13, 512)\n",
        "        self.fc2 = nn.Linear(512, 124)\n",
        "        self.fc3 = nn.Linear(124, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Model forward pass\n",
        "        :param x: List of image samples\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Z-F47NHWXBJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feovoIxMW2Bw",
        "outputId": "36aa0402-a218-4a87-9bd2-7c6798b84036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of to be trained model parameters: 6345886.\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "\n",
        "num_params = 0\n",
        "for param in net.parameters():\n",
        "    num_params += param.numel()\n",
        "\n",
        "print(\"Number of to be trained model parameters: {}.\".format(num_params))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ],
      "metadata": {
        "id": "JTyHf8N7biI2",
        "outputId": "bf0fe299-0564-462a-d1c0-1d115bd3177c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] notebook with cuda computation enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "USRBcwscbZ_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d3ea26-24dc-4996-cd97-682bdf77c557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 14:17:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = net.to(device)"
      ],
      "metadata": {
        "id": "DNN3-F-rbdll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBym1xNJW2Bw"
      },
      "source": [
        "## Train Model ##\n",
        "\n",
        "In this section we train our model with a cross-entropy loss utilizing stochasting gradiednt descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccUeWkhSW2Bw"
      },
      "outputs": [],
      "source": [
        "# Define optimization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "tS806fiBbfBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qxgfdpP0W2Bw",
        "outputId": "2bd9f09d-7dc3-416b-8df8-2dbbc525af78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20220521-14:17:31] epoch: 1 train-loss: 1.2495655044560183\n",
            "[LOG 20220521-14:17:38] epoch: 2 train-loss: 0.7225492377699269\n",
            "[LOG 20220521-14:17:45] epoch: 3 train-loss: 0.5199851150761283\n",
            "[LOG 20220521-14:17:51] epoch: 4 train-loss: 0.4070551106573846\n",
            "[LOG 20220521-14:17:58] epoch: 5 train-loss: 0.35387418210788923\n",
            "[LOG 20220521-14:18:04] epoch: 6 train-loss: 0.31791704674185167\n",
            "[LOG 20220521-14:18:11] epoch: 7 train-loss: 0.2868622368757759\n",
            "[LOG 20220521-14:18:17] epoch: 8 train-loss: 0.26557582051833095\n",
            "[LOG 20220521-14:18:24] epoch: 9 train-loss: 0.23800654451570238\n",
            "[LOG 20220521-14:18:31] epoch: 10 train-loss: 0.2165242787362275\n",
            "[LOG 20220521-14:18:37] epoch: 11 train-loss: 0.19528956457054444\n",
            "Saving model\n",
            "[LOG 20220521-14:18:44] epoch: 12 train-loss: 0.18068273457305692\n",
            "[LOG 20220521-14:18:51] epoch: 13 train-loss: 0.16692306932891715\n",
            "[LOG 20220521-14:18:58] epoch: 14 train-loss: 0.16431763231471816\n",
            "[LOG 20220521-14:19:04] epoch: 15 train-loss: 0.1416901783638091\n",
            "[LOG 20220521-14:19:11] epoch: 16 train-loss: 0.12906332884283991\n",
            "[LOG 20220521-14:19:18] epoch: 17 train-loss: 0.12326922287096344\n",
            "[LOG 20220521-14:19:25] epoch: 18 train-loss: 0.11287858236528121\n",
            "[LOG 20220521-14:19:31] epoch: 19 train-loss: 0.0994862656316486\n",
            "[LOG 20220521-14:19:38] epoch: 20 train-loss: 0.09525158631469684\n",
            "[LOG 20220521-14:19:45] epoch: 21 train-loss: 0.08966719806723968\n",
            "Saving model\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train_epoch_losses = []\n",
        "validation_epoch_losses = []\n",
        "\n",
        "epochs = 21\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    # init collection of mini-batch losses\n",
        "    train_mini_batch_losses = []\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader, 0):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # collect mini-batch reconstruction loss\n",
        "        train_mini_batch_losses.append(loss.data.item())\n",
        "            \n",
        "    # Per epoch store the training... \n",
        "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
        "    train_epoch_losses.append(train_epoch_loss)\n",
        "\n",
        "    # ...print statistics, ...\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "    print(f\"[LOG {now}] epoch: {epoch+1} train-loss: {train_epoch_loss}\")\n",
        "    # ...and save the model every 10 epochs\n",
        "    if (epoch) % 10 == 0 and epoch != 0:\n",
        "        if not os.path.exists(MODELS_PATH):\n",
        "            os.mkdir(MODELS_PATH)\n",
        "        print(\"Saving model\")\n",
        "        torch.save(\n",
        "            net.state_dict(), os.path.join(MODELS_PATH, f\"new_model_{epoch}.pth\")\n",
        "        )\n",
        "print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Delx76bW2By"
      },
      "source": [
        "## Create submission ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3l325siW2By"
      },
      "source": [
        "#### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHQQ-RotW2By",
        "outputId": "06deadf5-2d88-4052-b147-da0545744a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_model_10.pth  new_model_20.pth\n"
          ]
        }
      ],
      "source": [
        "!ls models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLBVLa6PW2By",
        "outputId": "47aae91a-5383-420b-c71d-16c3921e09ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "selected_model_path = \"new_model_20.pth\"\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(os.path.join(MODELS_PATH, selected_model_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIWXQ0WlW2By"
      },
      "source": [
        "#### Load submission data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rbngz/submission_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36a-j4uxqTS",
        "outputId": "f23b399d-0785-456a-d467-c69cb0b4042b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'submission_dataset'...\n",
            "remote: Enumerating objects: 4235, done.\u001b[K\n",
            "remote: Total 4235 (delta 0), reused 0 (delta 0), pack-reused 4235\u001b[K\n",
            "Receiving objects: 100% (4235/4235), 301.48 MiB | 12.05 MiB/s, done.\n",
            "Checking out files: 100% (4232/4232), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SUBMISSION_DATA_PATH = \"submission_dataset/testset\""
      ],
      "metadata": {
        "id": "3LIdPRDwzhcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_means_tuple = (\n",
        "    380.17328711583616,\n",
        "    400.1497676971955,\n",
        "    628.8646132355601,\n",
        "    578.870857455104,\n",
        "    943.4272711885449,\n",
        "    1826.2433534560898,\n",
        "    2116.6662455740857,\n",
        "    2205.972884006897,\n",
        "    2266.934157142567,\n",
        "    1487.6910683644517,\n",
        "    959.236167229867,\n",
        "    2281.1860589241937\n",
        ")\n",
        "submission_stds_tuple = (\n",
        "    115.17434877174112,\n",
        "    209.14842754591166,\n",
        "    241.20653977105658,\n",
        "    301.1056228200069,\n",
        "    269.5139533673432,\n",
        "    420.2497496130561,\n",
        "    503.8183661547185,\n",
        "    598.040304209199,\n",
        "    403.93781724898935,\n",
        "    398.143166872752,\n",
        "    342.44079144555366,\n",
        "    529.4133153492427\n",
        ")\n",
        "submission_normalizer = torchvision.transforms.Normalize(\n",
        "    submission_means_tuple, submission_stds_tuple\n",
        ")\n",
        "\n",
        "class SubmissionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, submission_samples, normalizer=submission_normalizer):\n",
        "        self.x = []\n",
        "        for _, submission_sample in tqdm(\n",
        "            sorted(\n",
        "                {\n",
        "                    # Sort files by index\n",
        "                    int(re.findall(\"\\d+\", submission_sample)[0]): submission_sample\n",
        "                    for submission_sample in submission_samples\n",
        "                }.items()\n",
        "            ),\n",
        "            desc=\"Loading submission samples\"\n",
        "        ):\n",
        "            # Extract bands\n",
        "            img = np.load(submission_sample)\n",
        "\n",
        "            # SWAP BANDS\n",
        "            tmp = img[:, :, 8].copy()\n",
        "            img = np.delete(img, 8, axis=2)\n",
        "            img = np.insert(img, 11, tmp, axis=2)\n",
        "\n",
        "            tens = torch.from_numpy(img.astype(int))\n",
        "            tens = tens.permute(2, 1, 0)\n",
        "\n",
        "            # Normalize\n",
        "            tens = normalizer(tens.float())\n",
        "            self.x.append(tens)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "metadata": {
        "id": "LszqRhIs6f4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "RoklI8Y-W2By",
        "outputId": "73ffbfdb-9619-4555-e590-cb731b364c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading submission samples: 100%|██████████| 4232/4232 [00:04<00:00, 970.15it/s]\n"
          ]
        }
      ],
      "source": [
        "submission_testset_samples = glob.glob(os.path.join(SUBMISSION_DATA_PATH, \"*.npy\"))\n",
        "submission_dataset = SubmissionDataset(submission_testset_samples)\n",
        "# Uncomment to create normalizer from scratch\n",
        "# submission_dataset = SubmissionDataset(submission_testset_samples,lambda x:x)\n",
        "# sub_normalizer = create_normalizer_for_dataset(submission_dataset, verbose=True)\n",
        "# del submission_dataset\n",
        "# submission_dataset = SubmissionDataset(submission_testset_samples, sub_normalizer)\n",
        "\n",
        "submission_dataloader = torch.utils.data.DataLoader(\n",
        "    submission_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHd-n0wuW2Bz"
      },
      "source": [
        "#### Create submission ####"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(net, submission_dataloader, filename: str = \"submission.csv\"):\n",
        "    \"\"\"\n",
        "    Helper method which creates a Kaggle submission from a given model and\n",
        "    :param net:\n",
        "    :param submission_dataloader:\n",
        "    :param filename:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    submission_results = []\n",
        "\n",
        "    index = 0\n",
        "    with torch.no_grad():\n",
        "        for images in iter(submission_dataloader):\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            label = classes_to_label[int(predicted[0])]\n",
        "            # Print predicted sample every once in a while\n",
        "            if index % 1000 == 0:\n",
        "                print(f\"Predicted: {label}\")\n",
        "            submission_results.append([index, label])\n",
        "            index += 1\n",
        "\n",
        "    # field names\n",
        "    fields = [\"test_id\", \"label\"]\n",
        "\n",
        "    # writing to csv file\n",
        "    with open(filename, \"w\") as csvfile:\n",
        "        # creating a csv writer object\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # writing the fields\n",
        "        csv_writer.writerow(fields)\n",
        "\n",
        "        # writing the data rows\n",
        "        csv_writer.writerows(submission_results)\n",
        "    print(f\"Submission was written to ./{filename}\")"
      ],
      "metadata": {
        "id": "RZGkmCDAXgw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77EynkFvW2Bz",
        "outputId": "ba734e32-8ee7-4402-e12b-298e8c294c02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Highway\n",
            "Predicted: Highway\n",
            "Predicted: River\n",
            "Predicted: Pasture\n",
            "Predicted: SeaLake\n",
            "Submission was written to ./submission.csv\n"
          ]
        }
      ],
      "source": [
        "create_submission(net, submission_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4rSbJI9W2Bz",
        "outputId": "8b44f40d-b1b1-4ace-925c-c7b6f191e8a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeaLake                 1012\n",
              "PermanentCrop            714\n",
              "Highway                  572\n",
              "River                    408\n",
              "AnnualCrop               393\n",
              "HerbaceousVegetation     365\n",
              "Pasture                  335\n",
              "Industrial               180\n",
              "Forest                   149\n",
              "Residential              104\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"submission.csv\")\n",
        "df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56onv8yW2Bz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "52335bc23b2686a5a24812a5c3b72ed0d36239717828f34470b0e14de89a5f4e"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Kopie von finalV2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}